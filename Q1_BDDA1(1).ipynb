{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('CoronavirusNLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Corona_NLP_train.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
      "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|\n",
      "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|\n",
      "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|\n",
      "|           Stay calm|          stay safe.|                null|                null|                null|     null|\n",
      "|#COVID19france #C...|            Positive|                null|                null|                null|     null|\n",
      "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|\n",
      "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|\n",
      "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|\n",
      "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|\n",
      "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|\n",
      "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|\n",
      "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|\n",
      "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|\n",
      "|The wait time may...| particularly bee...|                null|                null|                null|     null|\n",
      "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, UserName: string, ScreenName: string, Location: string, TweetAt: string, OriginalTweet: string, Sentiment: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68046, 6)\n"
     ]
    }
   ],
   "source": [
    "print((data.count(),len(data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('Tweet_length', length(data['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         111|\n",
      "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|         237|\n",
      "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|         131|\n",
      "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|          51|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|        null|\n",
      "|           Stay calm|          stay safe.|                null|                null|                null|     null|        null|\n",
      "|#COVID19france #C...|            Positive|                null|                null|                null|     null|        null|\n",
      "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|          60|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|        null|\n",
      "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|        null|\n",
      "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|         249|\n",
      "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|         184|\n",
      "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|          61|\n",
      "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|        null|\n",
      "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|         280|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|         267|\n",
      "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|         276|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|          79|\n",
      "|The wait time may...| particularly bee...|                null|                null|                null|     null|        null|\n",
      "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|        null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments= ['Positive','Negative','Neutral','Extremely Positive','Extremely Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby('Sentiment').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.filter(data.Sentiment.isin(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         Sentiment|\n",
      "+------------------+\n",
      "|Extremely Negative|\n",
      "|           Neutral|\n",
      "|          Positive|\n",
      "|          Negative|\n",
      "|Extremely Positive|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Sentiment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Sentiment').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|         Sentiment|count|\n",
      "+------------------+-----+\n",
      "|Extremely Negative| 3751|\n",
      "|           Neutral| 5224|\n",
      "|          Positive| 7718|\n",
      "|          Negative| 6857|\n",
      "|Extremely Positive| 4412|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|         Sentiment| avg(Tweet_length)|\n",
      "+------------------+------------------+\n",
      "|Extremely Negative| 209.6656891495601|\n",
      "|           Neutral| 151.2949846860643|\n",
      "|          Positive|193.66195905675045|\n",
      "|          Negative| 189.6651596908269|\n",
      "|Extremely Positive| 215.0605167724388|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Sentiment').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            Location| avg(Tweet_length)|\n",
      "+--------------------+------------------+\n",
      "|                 ...|             197.0|\n",
      "| Mumbai, Maharashtra|154.66666666666666|\n",
      "| Brisbane, Australia|             207.0|\n",
      "|West Woofle-Dust ...|             157.0|\n",
      "|   St Petersburg, FL|169.57142857142858|\n",
      "| All across Michigan|             224.0|\n",
      "|     Northumberland |             280.0|\n",
      "|     stoke on trent |             187.0|\n",
      "|some where around...|             126.0|\n",
      "|           Bangalore|176.21052631578948|\n",
      "|           Norn Iron|             244.0|\n",
      "|Horsham, Pennsylv...|             189.0|\n",
      "|       Shimla  India|              89.0|\n",
      "|Ferrara, Emilia R...|             230.0|\n",
      "|      Luton, England|             198.0|\n",
      "|              Heaven|             198.0|\n",
      "|       St George, UT|             188.0|\n",
      "|Just to the left ...|             205.0|\n",
      "|           Worcester|             258.5|\n",
      "|      Nellore/Canada|             280.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Location').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Location|count|\n",
      "+--------------------+-----+\n",
      "|                 ...|    1|\n",
      "| Mumbai, Maharashtra|    3|\n",
      "| Brisbane, Australia|    4|\n",
      "|West Woofle-Dust ...|    1|\n",
      "|   St Petersburg, FL|    7|\n",
      "| All across Michigan|    1|\n",
      "|     Northumberland |    1|\n",
      "|     stoke on trent |    1|\n",
      "|some where around...|    1|\n",
      "|           Bangalore|   19|\n",
      "|           Norn Iron|    1|\n",
      "|Horsham, Pennsylv...|    1|\n",
      "|       Shimla  India|    1|\n",
      "|Ferrara, Emilia R...|    1|\n",
      "|      Luton, England|    1|\n",
      "|              Heaven|    1|\n",
      "|       St George, UT|    1|\n",
      "|Just to the left ...|    1|\n",
      "|           Worcester|    2|\n",
      "|      Nellore/Canada|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Location').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|Tweet_length|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|         111|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|         237|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|         131|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|         249|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|         184|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|         280|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|         267|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|         276|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|         278|\n",
      "|    3813|     48765|                null|16-03-2020|ADARA Releases CO...|          Positive|         185|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|         184|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|         251|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|         255|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|         278|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|         202|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|         279|\n",
      "|    3829|     48781|                null|16-03-2020|There Is of in th...|          Negative|         114|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|         122|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|         225|\n",
      "|    3837|     48789|                null|16-03-2020|my wife works ret...|          Negative|         288|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27962, 7)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan,when,count,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|       0|         0|    6152|      0|            0|        0|           0|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"OriginalTweet\", outputCol = \"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol=\"token_text\", outputCol = \"stop_tokens\")\n",
    "#Cleaned version of Tokens\n",
    "#Counting Occurnace of tokens\n",
    "count_vec = CountVectorizer(inputCol = \"stop_tokens\", outputCol = \"c_vec\")\n",
    "idf = IDF(inputCol = \"c_vec\", outputCol = \"tf_idf\")\n",
    "\n",
    "Corona_to_num = StringIndexer(inputCol = \"Sentiment\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols =[\"tf_idf\", \"Tweet_length\"], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB= NaiveBayes()\n",
    "RF = RandomForestClassifier(numTrees = 50)\n",
    "DTC = DecisionTreeClassifier (maxDepth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline = Pipeline(stages =[Corona_to_num,tokenizer, stopremove,count_vec,idf,clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|Tweet_length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|         111|  2.0|[@menyrbie, @phil...|[@menyrbie, @phil...|(78305,[14499,289...|(78305,[14499,289...|(78306,[14499,289...|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|         237|  0.0|[advice, talk, to...|[advice, talk, ne...|(78305,[13,14,133...|(78305,[13,14,133...|(78306,[13,14,133...|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|         131|  0.0|[coronavirus, aus...|[coronavirus, aus...|(78305,[8,14,37,7...|(78305,[8,14,37,7...|(78306,[8,14,37,7...|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|         249|  0.0|[as, news, of, th...|[news, regions, ...|(78305,[7,8,31,47...|(78305,[7,8,31,47...|(78306,[7,8,31,47...|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|         184|  0.0|[\"cashier, at, gr...|[\"cashier, grocer...|(78305,[3,6,18,60...|(78305,[3,6,18,60...|(78306,[3,6,18,60...|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|         280|  0.0|[due, to, covid-1...|[due, covid-19, r...|(78305,[1,6,8,13,...|(78305,[1,6,8,13,...|(78306,[1,6,8,13,...|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|         267|  1.0|[for, corona, pre...|[corona, preventi...|(78305,[11,13,14,...|(78305,[11,13,14,...|(78306,[11,13,14,...|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|         276|  2.0|[all, month, ther...|[month, crowding,...|(78305,[48,70,147...|(78305,[48,70,147...|(78306,[48,70,147...|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|         278|  3.0|[#horningsea, is,...|[#horningsea, car...|(78305,[13,14,23,...|(78305,[13,14,23,...|(78306,[13,14,23,...|\n",
      "|    3813|     48765|                null|16-03-2020|ADARA Releases CO...|          Positive|         185|  0.0|[adara, releases,...|[adara, releases,...|(78305,[8,10,23,5...|(78305,[8,10,23,5...|(78306,[8,10,23,5...|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|         184|  0.0|[for, those, who,...|[struggling,, ple...|(78305,[4,8,24,38...|(78305,[4,8,24,38...|(78306,[4,8,24,38...|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|         251|  4.0|[with, 100, , nat...|[100, , nations, ...|(78305,[1,4,9,11,...|(78305,[1,4,9,11,...|(78306,[1,4,9,11,...|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|         255|  1.0|[@10downingstreet...|[@10downingstreet...|(78305,[4,21,44,7...|(78305,[4,21,44,7...|(78306,[4,21,44,7...|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|         278|  3.0|[uk, #consumer, p...|[uk, #consumer, p...|(78305,[10,37,54,...|(78305,[10,37,54,...|(78306,[10,37,54,...|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|         202|  1.0|[in, preparation,...|[preparation, hig...|(78305,[4,8,24,33...|(78305,[4,8,24,33...|(78306,[4,8,24,33...|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|         279|  4.0|[this, morning, i...|[morning, tested,...|(78305,[1,7,11,36...|(78305,[1,7,11,36...|(78306,[1,7,11,36...|\n",
      "|    3829|     48781|                null|16-03-2020|There Is of in th...|          Negative|         114|  1.0|[there, is, of, i...|[country, , empty...|(78305,[1,4,7,34,...|(78305,[1,4,7,34,...|(78306,[1,4,7,34,...|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|         122|  2.0|[went, to, the, s...|[went, supermarke...|(78305,[5,47,48,6...|(78305,[5,47,48,6...|(78306,[5,47,48,6...|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|         225|  0.0|[worried, about, ...|[worried, impact,...|(78305,[8,12,23,2...|(78305,[8,12,23,2...|(78306,[8,12,23,2...|\n",
      "|    3837|     48789|                null|16-03-2020|my wife works ret...|          Negative|         288|  1.0|[my, wife, works,...|[wife, works, ret...|(78305,[6,28,33,9...|(78305,[6,28,33,9...|(78306,[6,28,33,9...|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select(['label','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|(78306,[14499,289...|\n",
      "|  0.0|(78306,[13,14,133...|\n",
      "|  0.0|(78306,[8,14,37,7...|\n",
      "|  0.0|(78306,[7,8,31,47...|\n",
      "|  0.0|(78306,[3,6,18,60...|\n",
      "|  0.0|(78306,[1,6,8,13,...|\n",
      "|  1.0|(78306,[11,13,14,...|\n",
      "|  2.0|(78306,[48,70,147...|\n",
      "|  3.0|(78306,[13,14,23,...|\n",
      "|  0.0|(78306,[8,10,23,5...|\n",
      "|  0.0|(78306,[4,8,24,38...|\n",
      "|  4.0|(78306,[1,4,9,11,...|\n",
      "|  1.0|(78306,[4,21,44,7...|\n",
      "|  3.0|(78306,[10,37,54,...|\n",
      "|  1.0|(78306,[4,8,24,33...|\n",
      "|  4.0|(78306,[1,7,11,36...|\n",
      "|  1.0|(78306,[1,4,7,34,...|\n",
      "|  2.0|(78306,[5,47,48,6...|\n",
      "|  0.0|(78306,[8,12,23,2...|\n",
      "|  1.0|(78306,[6,28,33,9...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training,testing)=clean_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictNB = NB.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictRF= RF.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_results = PredictNB.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_results = PredictRF.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTC_results = PredictDTC.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(78306,[0,1,2,7,1...|[-1207.2654728345...|[1.23172711334096...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,12,...|[-1155.6053393367...|[4.49669991632944...|       3.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[-1247.5586027990...|[0.99992116013007...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[-1388.3384940412...|[5.52243859179497...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,29,...|[-1850.6003542964...|[2.37600010972831...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,30,...|[-2398.4784545940...|[0.99998786596188...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,40,...|[-1477.6725368856...|[6.24553590260341...|       2.0|\n",
      "|  0.0|(78306,[0,1,3,4,6...|[-1168.4420450442...|[6.68937393488242...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,4,1...|[-1221.7800777800...|[5.24914792017073...|       2.0|\n",
      "|  0.0|(78306,[0,1,3,6,7...|[-1305.2735048418...|[4.13570016258484...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1088.0861543391...|[8.99506281025307...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1000.2148739507...|[1.09861119558768...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1132.1674175135...|[0.07463808854436...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-955.71473580545...|[6.06690534440760...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1769.4531357523...|[1.36957733619516...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-668.95705224869...|[0.01454524823461...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,2...|[-2239.6295000709...|[6.62617176027843...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[-1942.7170234589...|[0.80789690040752...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-937.11022960676...|[1.28938581460795...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,7,1...|[-1719.3600370578...|[5.50314673745056...|       3.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(78306,[0,1,2,7,1...|[13.9174724015062...|[0.27834944803012...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,12,...|[14.4229994994904...|[0.28845998998980...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[13.9739187701817...|[0.27947837540363...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[13.8970632598946...|[0.27794126519789...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,29,...|[13.7672246487022...|[0.27534449297404...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,30,...|[14.1322917944135...|[0.28264583588827...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,40,...|[14.0790984865649...|[0.28158196973129...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,4,6...|[14.0381486927753...|[0.28076297385550...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,4,1...|[14.0958876813158...|[0.28191775362631...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,7...|[14.0173479273081...|[0.28034695854616...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0884883822251...|[0.28176976764450...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.2339073223475...|[0.28467814644695...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0884883822251...|[0.28176976764450...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0884883822251...|[0.28176976764450...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0942826517415...|[0.28188565303483...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0166820121111...|[0.28033364024222...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,2...|[14.1821258250740...|[0.28364251650148...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[14.1299690955647...|[0.28259938191129...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[14.0239343467383...|[0.28047868693476...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,7,1...|[13.8297731568071...|[0.27659546313614...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTC_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = MulticlassClassificationEvaluator()\n",
    "acc_NB = eva.evaluate(NB_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = MulticlassClassificationEvaluator()\n",
    "acc_RF = eva.evaluate(RF_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the NB and RF is :: 0.4050110016069719 0.11208634595726202\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of the NB and RF is ::\", acc_NB, acc_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
